# Implementation Plan: Local Query Coverage Analytics

**Branch**: `001-add-query-analytics` | **Date**: 2025-10-21 | **Spec**: `/specs/001-add-query-analytics/spec.md`
**Input**: Feature specification from `/specs/001-add-query-analytics/spec.md`

**Note**: This template is filled in by the `/speckit.plan` command. See `.specify/templates/commands/plan.md` for the execution workflow.

## Summary

Deliver a local-only Streamlit experience that ingests CSV/Excel files, embeds user-selected text columns with SentenceTransformers, stores embeddings in ChromaDB, and powers instant semantic search plus coverage analytics while persisting labeling/analytics metadata in SQLite without materializing duplicate processed files.

## Technical Context

**Language/Runtime**: Python 3.11 Streamlit application managed with Poetry for reproducible local installs.  
**Quality Tooling**: Enforce black (format), ruff (lint/import order), mypy (strict typing), and pytest with coverage gates in CI.  
**Testing Strategy**: Unit tests for ingestion/embedding pipelines, integration suites against ChromaDB collections, and `pytest-benchmark` performance tests validating <1s search and <5-minute ingestion using fixture datasets capped at 100k rows.  
**User Experience Framework**: Streamlit multipage layout with accessibility checklist (keyboard flow, contrast, screen reader annotations) and manual QA notes captured in quickstart.  
**Performance Budgets**: Search P95 < 1s for 20 results against 100k vectors; ingestion pipeline < 5 minutes for 100k rows; analytics charts render < 2s.  
**Dependencies**: Streamlit, pandas with `pyarrow` CSV acceleration, `openpyxl` for Excel, SentenceTransformers (`all-MiniLM-L6-v2` default), ChromaDB persistent client, Plotly Express visualizations, SQLite for metadata/audit logging.  
**Data & Storage**: Local `data/` root retaining original uploads (`data/raw/`) and embedded vectors in ChromaDB; labeling, clustering parameters, and analytics metadata persisted in SQLite tables or ChromaDB metadata so users see them on subsequent runs, with no intermediary processed-file directory.  
**Scale/Scope**: Single-user desktop usage, sequential ingestion jobs, dataset sizes up to 100k rows per import, concurrent read/search interactions during analysis.

## Constitution Check

*GATE: Must pass before Phase 0 research. Re-check after Phase 1 design.*

- Map modules and dependencies to approved coding standards, architectural boundaries, and documentation updates.  
  - Apply Poetry-managed Python 3.11 environment, codify modules for ingestion, embeddings, search, analytics, and record data flows that keep raw-source storage canonical while persisting labels/analytics in SQLite metadata instead of duplicate processed files.  
  - Document adoption of Plotly and SQLite metadata store; ensure architecture diagrams capture ChromaDB collection design and metadata persistence.
- Provide test coverage targets, required suites (unit, integration, performance), and evidence of failure-first execution.  
  - Target >=85% coverage overall and 100% for ingestion and search critical paths using pytest with fixture datasets.  
  - Implement repeatable performance smoke tests via `pytest-benchmark` for ingestion throughput and search latency, running in CI before merge.
- Document UX patterns, accessibility approach, and consistency checks planned for this work.  
  - Use Streamlit components with documented keyboard navigation, focus order, and color contrast checks; attach QA checklist in quickstart.  
  - Align copy/layout with Unified User Experience guidelines; capture walkthrough updates in quickstart.md.
- Define performance budgets, instrumentation strategy, and how results will be reported in CI/release notes.  
  - Instrument ingestion, embedding, search, and dashboard render timing with structured logs persisted alongside SQLite metadata; summarize metrics in release checklist.  
  - Maintain benchmark scenarios under `tests/performance/` with stored baseline JSON for comparison.
- Identify any principle waivers, governance approvals, or decision records required before implementation.  
  - No waivers requested; Streamlit, ChromaDB, SentenceTransformers, Plotly Express, and SQLite fall within approved local-first stack.  
  - Document storage policy (raw source files + persisted metadata, no duplicate processed outputs); no additional approvals anticipated.

**Post-Design Review**: Phase 1 artifacts (`research.md`, `data-model.md`, `contracts/openapi.yaml`, `quickstart.md`) align with constitution gates; quality, UX, and performance evidence plans documented without outstanding violations.

## Project Structure

### Documentation (this feature)

```
specs/001-add-query-analytics/
├── plan.md
├── research.md
├── data-model.md
├── quickstart.md
├── contracts/
└── tasks.md        # Not generated by /speckit.plan
```

### Source Code (repository root)

```
app/
├── main.py
├── pages/
│   ├── 1_ingest.py
│   ├── 2_search.py
│   └── 3_analytics.py
├── services/
│   ├── ingestion.py
│   ├── embeddings.py
│   ├── search.py
│   └── analytics.py
├── db/
│   ├── metadata.py
│   └── schema.py
├── api/
│   ├── router.py
│   └── schemas.py
└── utils/
    ├── caching.py
    └── logging.py

tests/
├── unit/
│   ├── test_ingestion.py
│   ├── test_embeddings.py
│   ├── test_search.py
│   └── test_analytics.py
├── integration/
│   ├── test_search_api.py
│   └── test_ingest_workflow.py
└── performance/
    ├── test_ingestion_bench.py
    └── test_search_latency.py
```

**Structure Decision**: Single Streamlit project under `app/` with service modules separated by concern and supporting API router; dedicated `tests/` hierarchy for unit, integration, and performance suites aligned with Evidence-Driven Testing.

## Complexity Tracking

*Fill ONLY if Constitution Check has violations that must be justified*

| Violation | Why Needed | Simpler Alternative Rejected Because |
|-----------|------------|-------------------------------------|
